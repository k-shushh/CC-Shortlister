{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "753fed86-12f4-4fe8-ba91-b9e3216e91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "import pdfplumber\n",
    "import docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "601f00aa-3979-48bd-bba2-a31be782f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(file_path: str) -> str:\n",
    "    fp = file_path.lower()\n",
    "    if fp.endswith(\".pdf\"):\n",
    "        out = []\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            for p in pdf.pages:\n",
    "                out.append(p.extract_text() or \"\")\n",
    "        return \"\\n\".join(out)\n",
    "\n",
    "    if fp.endswith(\".docx\"):\n",
    "        d = docx.Document(file_path)\n",
    "        parts = []\n",
    "\n",
    "        \n",
    "        for para in d.paragraphs:\n",
    "            parts.append(para.text or \"\")\n",
    "\n",
    "       \n",
    "        for tbl in d.tables:\n",
    "            for row in tbl.rows:\n",
    "                for cell in row.cells:\n",
    "                    for para in cell.paragraphs:\n",
    "                        parts.append(para.text or \"\")\n",
    "\n",
    "       \n",
    "        try:\n",
    "            for sec in d.sections:\n",
    "                for para in sec.header.paragraphs:\n",
    "                    parts.append(para.text or \"\")\n",
    "                for para in sec.footer.paragraphs:\n",
    "                    parts.append(para.text or \"\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        return \"\\n\".join(parts)\n",
    "\n",
    "    if fp.endswith(\".txt\"):\n",
    "        return open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\").read()\n",
    "\n",
    "    raise ValueError(\"Unsupported file format: Only .pdf, .docx, .txt are supported\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "100ee6f9-2f21-4d3f-bdd6-3ac20caaf109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_projects_improved(text):\n",
    "    lines = text.splitlines()\n",
    "    start = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if re.search(r\"\\bprojects?\\b\", line, re.IGNORECASE):\n",
    "            start = i + 1\n",
    "            break\n",
    "    if start is None:\n",
    "        print(\"Projects section not found.\")\n",
    "        return []\n",
    "    stop_sections = {\"STRENGTHS\", \"DECLARATION\", \"CERTIFICATIONS\", \"EDUCATION\", \"SKILLS\", \"EXPERIENCE\", \"ACHIEVEMENTS\"}\n",
    "    buf = []\n",
    "    for line in lines[start:]:\n",
    "        striped_line = line.strip()\n",
    "        if striped_line.upper() in stop_sections:\n",
    "            break\n",
    "        buf.append(striped_line)\n",
    "    projects = []\n",
    "    current_project = []\n",
    "    for line in buf:\n",
    "        if re.match(r\"^[A-Z\\s]+$\", line) and len(line) > 3:\n",
    "            if current_project:\n",
    "                projects.append(\" \".join(current_project).strip())\n",
    "                current_project = []\n",
    "            current_project.append(line)\n",
    "        else:\n",
    "            if line != \"\":\n",
    "                current_project.append(line)\n",
    "    if current_project:\n",
    "        projects.append(\" \".join(current_project).strip())\n",
    "    return projects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8d711ff3-33db-4a8e-b4c4-be687271c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_certifications(text):\n",
    "    lines = text.splitlines()\n",
    "    start = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if re.search(r\"\\bcertifications?\\b\", line, re.IGNORECASE):\n",
    "            start = i + 1\n",
    "            break\n",
    "    if start is None:\n",
    "        print(\"Certifications section not found.\")\n",
    "        return []\n",
    "    stop_sections = {\"STRENGTHS\", \"DECLARATION\", \"PROJECTS\", \"EDUCATION\", \"SKILLS\", \"EXPERIENCE\", \"ACHIEVEMENTS\"}\n",
    "    buf = []\n",
    "    for line in lines[start:]:\n",
    "        striped_line = line.strip()\n",
    "        if striped_line.upper() in stop_sections:\n",
    "            break\n",
    "        if striped_line != \"\":\n",
    "            buf.append(striped_line)\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6aa0c772-e896-4264-96fd-cfb5e97f9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_achievements(text):\n",
    "    lines = text.splitlines()\n",
    "    start = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if re.search(r\"\\bachievements?\\b\", line, re.IGNORECASE):\n",
    "            start = i + 1\n",
    "            break\n",
    "    if start is None:\n",
    "        print(\"Achievements section not found.\")\n",
    "        return []\n",
    "    stop_sections = {\"STRENGTHS\", \"DECLARATION\", \"PROJECTS\", \"EDUCATION\", \"SKILLS\", \"EXPERIENCE\", \"CERTIFICATIONS\"}\n",
    "    buf = []\n",
    "    for line in lines[start:]:\n",
    "        striped_line = line.strip()\n",
    "        if striped_line.upper() in stop_sections:\n",
    "            break\n",
    "        if striped_line != \"\":\n",
    "            buf.append(striped_line)\n",
    "    return buf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7a68bb84-f5cf-412e-be06-870884a9288b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Projects ====\n",
      "\n",
      "---\n",
      "\n",
      "CROSS PLATFORM REPUTATION GENERATION SYSTEM BASED ON ASPECT BAESD SENTIMENT ANALYSIS Developed a cross-platform reputation system capable of collecting and standardizing opinions from diverse platforms (Facebook, Amazon, Twitter, Trip Advisor), ensuring comprehensive and accurate reputation analysis. Implemented advanced spam filtering using behavioral features to detect and eliminate spam, ensuring the authenticity of opinions used in the reputation calculation. Tools & Algorithms used: Python, Extra tree classifier, SVM algorithm, and logistic regression.\n",
      "\n",
      "---\n",
      "\n",
      "ACTION ASSIST Built a voice assistant which can translate and communicate in regional language (Telugu) Developed project using Libraries SpeechRecognition, google-cloud-speech, pyaudio(Converts speech to text, enabling voice input). Designed and Developed NLP with Django Framework. Translates text between languages (e.g., English to Telugu) by using Translation libraries( googletrans, google-cloud-translate). Converts text into speech to respond to the user by Text-to-Speech. Tools used: Python\n",
      "\n",
      "==== Certifications ====\n",
      "Certified by Surge Classes for completion of Data science and AI campus program.\n",
      "Certified by Spoken Tutorial for completion of C++, JAVA, Python Programming\n",
      "Certificate of completion for AWS Academy Cloud Foundations & AWS Academy Machine Learning\n",
      "Achievements section not found.\n",
      "\n",
      "==== Achievements ====\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_path = r\"C:\\Users\\akhil\\OneDrive\\Documents\\Akhila 2 resume (2).docx\"\n",
    "    raw_text = extract_text(file_path)\n",
    "    \n",
    "    projects = extract_projects_improved(raw_text)\n",
    "    print(\"==== Projects ====\")\n",
    "    for p in projects:\n",
    "        print(\"\\n---\\n\")\n",
    "        print(p)\n",
    "    \n",
    "    certifications = extract_certifications(raw_text)\n",
    "    print(\"\\n==== Certifications ====\")\n",
    "    for cert in certifications:\n",
    "        print(cert)\n",
    "    \n",
    "    achievements = extract_achievements(raw_text)\n",
    "    print(\"\\n==== Achievements ====\")\n",
    "    for ach in achievements:\n",
    "        print(ach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af266c8-0c80-4a63-be63-14e042550a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (resume-ner)",
   "language": "python",
   "name": "resume-ner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
